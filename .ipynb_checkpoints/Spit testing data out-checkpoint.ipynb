{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import helper as hp\n",
    "\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(filename):\n",
    "    dataframe = pd.read_csv(filename)\n",
    "    dataframe.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "    print('Found {} rows '.format(str(len(dataframe))))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7224612 rows \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lube</td>\n",
       "      <td>/2425/1/115_Lube_45484.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spencerian</td>\n",
       "      <td>/2425/1/114_Spencerian_73323.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accommodatingly</td>\n",
       "      <td>/2425/1/113_accommodatingly_613.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CARPENTER</td>\n",
       "      <td>/2425/1/112_CARPENTER_11682.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REGURGITATING</td>\n",
       "      <td>/2425/1/111_REGURGITATING_64100.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                 path\n",
       "0             Lube           /2425/1/115_Lube_45484.jpg\n",
       "1       Spencerian     /2425/1/114_Spencerian_73323.jpg\n",
       "2  accommodatingly  /2425/1/113_accommodatingly_613.jpg\n",
       "3        CARPENTER      /2425/1/112_CARPENTER_11682.jpg\n",
       "4    REGURGITATING  /2425/1/111_REGURGITATING_64100.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_df = load_dataframe('full_datasets/all_train.csv')\n",
    "all_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 802734 rows \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MONIKER</td>\n",
       "      <td>/2697/6/466_MONIKER_49537.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecclesiastics</td>\n",
       "      <td>/2697/6/465_Ecclesiastics_24500.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIRESTORM</td>\n",
       "      <td>/2697/6/464_FIRESTORM_29099.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Psi</td>\n",
       "      <td>/2697/6/463_Psi_60982.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Repurchases</td>\n",
       "      <td>/2697/6/462_Repurchases_64997.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                                 path\n",
       "0        MONIKER        /2697/6/466_MONIKER_49537.jpg\n",
       "1  Ecclesiastics  /2697/6/465_Ecclesiastics_24500.jpg\n",
       "2      FIRESTORM      /2697/6/464_FIRESTORM_29099.jpg\n",
       "3            Psi            /2697/6/463_Psi_60982.jpg\n",
       "4    Repurchases    /2697/6/462_Repurchases_64997.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_valid_df = load_dataframe('full_datasets/all_validation.csv')\n",
    "all_valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 891927 rows \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slinking</td>\n",
       "      <td>/3000/7/182_slinking_71711.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REMODELERS</td>\n",
       "      <td>/3000/7/181_REMODELERS_64541.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chronographs</td>\n",
       "      <td>/3000/7/180_Chronographs_13538.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impeaching</td>\n",
       "      <td>/3000/7/179_Impeaching_38222.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discombobulated</td>\n",
       "      <td>/3000/7/178_discombobulated_22063.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                   path\n",
       "0         slinking         /3000/7/182_slinking_71711.jpg\n",
       "1       REMODELERS       /3000/7/181_REMODELERS_64541.jpg\n",
       "2     Chronographs     /3000/7/180_Chronographs_13538.jpg\n",
       "3       Impeaching       /3000/7/179_Impeaching_38222.jpg\n",
       "4  discombobulated  /3000/7/178_discombobulated_22063.jpg"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_df = load_dataframe('full_datasets/all_test.csv')\n",
    "all_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_directory(df):\n",
    "    directory = hp.assets_directory()\n",
    "    df['full_path'] = directory + df['path']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 100000\n",
      "Validation dataset size: 20000\n",
      "Test dataset size: 20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5996700</th>\n",
       "      <td>Eerier</td>\n",
       "      <td>/408/3/125_Eerier_24690.jpg</td>\n",
       "      <td>/Users/jbenavidesv/Workspace/ocr_detector/90kD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416676</th>\n",
       "      <td>Begets</td>\n",
       "      <td>/944/3/62_Begets_6696.jpg</td>\n",
       "      <td>/Users/jbenavidesv/Workspace/ocr_detector/90kD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950801</th>\n",
       "      <td>hutches</td>\n",
       "      <td>/1771/3/462_hutches_37481.jpg</td>\n",
       "      <td>/Users/jbenavidesv/Workspace/ocr_detector/90kD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829770</th>\n",
       "      <td>lobbyist</td>\n",
       "      <td>/1141/4/369_lobbyist_44975.jpg</td>\n",
       "      <td>/Users/jbenavidesv/Workspace/ocr_detector/90kD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786390</th>\n",
       "      <td>cheekiest</td>\n",
       "      <td>/814/6/233_cheekiest_12962.jpg</td>\n",
       "      <td>/Users/jbenavidesv/Workspace/ocr_detector/90kD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                            path  \\\n",
       "5996700     Eerier     /408/3/125_Eerier_24690.jpg   \n",
       "4416676     Begets       /944/3/62_Begets_6696.jpg   \n",
       "1950801    hutches   /1771/3/462_hutches_37481.jpg   \n",
       "3829770   lobbyist  /1141/4/369_lobbyist_44975.jpg   \n",
       "4786390  cheekiest  /814/6/233_cheekiest_12962.jpg   \n",
       "\n",
       "                                                 full_path  \n",
       "5996700  /Users/jbenavidesv/Workspace/ocr_detector/90kD...  \n",
       "4416676  /Users/jbenavidesv/Workspace/ocr_detector/90kD...  \n",
       "1950801  /Users/jbenavidesv/Workspace/ocr_detector/90kD...  \n",
       "3829770  /Users/jbenavidesv/Workspace/ocr_detector/90kD...  \n",
       "4786390  /Users/jbenavidesv/Workspace/ocr_detector/90kD...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = all_train_df.sample(100000)\n",
    "valid_df = all_valid_df.sample(20000)\n",
    "test_df = all_test_df.sample(20000)\n",
    "\n",
    "train_df = create_full_directory(train_df)\n",
    "valid_df = create_full_directory(valid_df)\n",
    "test_df = create_full_directory(test_df)\n",
    "\n",
    "print('Training dataset size: ' + str(len(train_df)))\n",
    "print('Validation dataset size: ' + str(len(valid_df)))\n",
    "print('Test dataset size: ' + str(len(test_df)))\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_files(root, df):\n",
    "    print('\\n')\n",
    "    paths = df['path'].values\n",
    "    full_paths = df['full_path'].values\n",
    "    \n",
    "    print('\\n')\n",
    "    print('Processing ' + str(root))\n",
    "    for idx in range(0, len(paths)):\n",
    "        path = paths[idx]\n",
    "        f_path = full_paths[idx]\n",
    "        \n",
    "        if idx % 500 == 0:\n",
    "            print('Processed {} images of {}'.format(idx, len(paths)))\n",
    "        \n",
    "        dest_path = root + path\n",
    "        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "        shutil.copy(f_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing demo/train\n",
      "Processed 0 images of 100000\n",
      "Processed 500 images of 100000\n",
      "Processed 1000 images of 100000\n",
      "Processed 1500 images of 100000\n",
      "Processed 2000 images of 100000\n",
      "Processed 2500 images of 100000\n",
      "Processed 3000 images of 100000\n",
      "Processed 3500 images of 100000\n",
      "Processed 4000 images of 100000\n",
      "Processed 4500 images of 100000\n",
      "Processed 5000 images of 100000\n",
      "Processed 5500 images of 100000\n",
      "Processed 6000 images of 100000\n",
      "Processed 6500 images of 100000\n",
      "Processed 7000 images of 100000\n",
      "Processed 7500 images of 100000\n",
      "Processed 8000 images of 100000\n",
      "Processed 8500 images of 100000\n",
      "Processed 9000 images of 100000\n",
      "Processed 9500 images of 100000\n",
      "Processed 10000 images of 100000\n",
      "Processed 10500 images of 100000\n",
      "Processed 11000 images of 100000\n",
      "Processed 11500 images of 100000\n",
      "Processed 12000 images of 100000\n",
      "Processed 12500 images of 100000\n",
      "Processed 13000 images of 100000\n",
      "Processed 13500 images of 100000\n",
      "Processed 14000 images of 100000\n",
      "Processed 14500 images of 100000\n",
      "Processed 15000 images of 100000\n",
      "Processed 15500 images of 100000\n",
      "Processed 16000 images of 100000\n",
      "Processed 16500 images of 100000\n",
      "Processed 17000 images of 100000\n",
      "Processed 17500 images of 100000\n",
      "Processed 18000 images of 100000\n",
      "Processed 18500 images of 100000\n",
      "Processed 19000 images of 100000\n",
      "Processed 19500 images of 100000\n",
      "Processed 20000 images of 100000\n",
      "Processed 20500 images of 100000\n",
      "Processed 21000 images of 100000\n",
      "Processed 21500 images of 100000\n",
      "Processed 22000 images of 100000\n",
      "Processed 22500 images of 100000\n",
      "Processed 23000 images of 100000\n",
      "Processed 23500 images of 100000\n",
      "Processed 24000 images of 100000\n",
      "Processed 24500 images of 100000\n",
      "Processed 25000 images of 100000\n",
      "Processed 25500 images of 100000\n",
      "Processed 26000 images of 100000\n",
      "Processed 26500 images of 100000\n",
      "Processed 27000 images of 100000\n",
      "Processed 27500 images of 100000\n",
      "Processed 28000 images of 100000\n",
      "Processed 28500 images of 100000\n",
      "Processed 29000 images of 100000\n",
      "Processed 29500 images of 100000\n",
      "Processed 30000 images of 100000\n",
      "Processed 30500 images of 100000\n",
      "Processed 31000 images of 100000\n",
      "Processed 31500 images of 100000\n",
      "Processed 32000 images of 100000\n",
      "Processed 32500 images of 100000\n",
      "Processed 33000 images of 100000\n",
      "Processed 33500 images of 100000\n",
      "Processed 34000 images of 100000\n",
      "Processed 34500 images of 100000\n",
      "Processed 35000 images of 100000\n",
      "Processed 35500 images of 100000\n",
      "Processed 36000 images of 100000\n",
      "Processed 36500 images of 100000\n",
      "Processed 37000 images of 100000\n",
      "Processed 37500 images of 100000\n",
      "Processed 38000 images of 100000\n",
      "Processed 38500 images of 100000\n",
      "Processed 39000 images of 100000\n",
      "Processed 39500 images of 100000\n",
      "Processed 40000 images of 100000\n",
      "Processed 40500 images of 100000\n",
      "Processed 41000 images of 100000\n",
      "Processed 41500 images of 100000\n",
      "Processed 42000 images of 100000\n",
      "Processed 42500 images of 100000\n",
      "Processed 43000 images of 100000\n",
      "Processed 43500 images of 100000\n",
      "Processed 44000 images of 100000\n",
      "Processed 44500 images of 100000\n",
      "Processed 45000 images of 100000\n",
      "Processed 45500 images of 100000\n",
      "Processed 46000 images of 100000\n",
      "Processed 46500 images of 100000\n",
      "Processed 47000 images of 100000\n",
      "Processed 47500 images of 100000\n",
      "Processed 48000 images of 100000\n",
      "Processed 48500 images of 100000\n",
      "Processed 49000 images of 100000\n",
      "Processed 49500 images of 100000\n",
      "Processed 50000 images of 100000\n",
      "Processed 50500 images of 100000\n",
      "Processed 51000 images of 100000\n",
      "Processed 51500 images of 100000\n",
      "Processed 52000 images of 100000\n",
      "Processed 52500 images of 100000\n",
      "Processed 53000 images of 100000\n",
      "Processed 53500 images of 100000\n",
      "Processed 54000 images of 100000\n",
      "Processed 54500 images of 100000\n",
      "Processed 55000 images of 100000\n",
      "Processed 55500 images of 100000\n",
      "Processed 56000 images of 100000\n",
      "Processed 56500 images of 100000\n",
      "Processed 57000 images of 100000\n",
      "Processed 57500 images of 100000\n",
      "Processed 58000 images of 100000\n",
      "Processed 58500 images of 100000\n",
      "Processed 59000 images of 100000\n",
      "Processed 59500 images of 100000\n",
      "Processed 60000 images of 100000\n",
      "Processed 60500 images of 100000\n",
      "Processed 61000 images of 100000\n",
      "Processed 61500 images of 100000\n",
      "Processed 62000 images of 100000\n",
      "Processed 62500 images of 100000\n",
      "Processed 63000 images of 100000\n",
      "Processed 63500 images of 100000\n",
      "Processed 64000 images of 100000\n",
      "Processed 64500 images of 100000\n",
      "Processed 65000 images of 100000\n",
      "Processed 65500 images of 100000\n",
      "Processed 66000 images of 100000\n",
      "Processed 66500 images of 100000\n",
      "Processed 67000 images of 100000\n",
      "Processed 67500 images of 100000\n",
      "Processed 68000 images of 100000\n",
      "Processed 68500 images of 100000\n",
      "Processed 69000 images of 100000\n",
      "Processed 69500 images of 100000\n",
      "Processed 70000 images of 100000\n",
      "Processed 70500 images of 100000\n",
      "Processed 71000 images of 100000\n",
      "Processed 71500 images of 100000\n",
      "Processed 72000 images of 100000\n",
      "Processed 72500 images of 100000\n",
      "Processed 73000 images of 100000\n",
      "Processed 73500 images of 100000\n",
      "Processed 74000 images of 100000\n",
      "Processed 74500 images of 100000\n",
      "Processed 75000 images of 100000\n",
      "Processed 75500 images of 100000\n",
      "Processed 76000 images of 100000\n",
      "Processed 76500 images of 100000\n",
      "Processed 77000 images of 100000\n",
      "Processed 77500 images of 100000\n",
      "Processed 78000 images of 100000\n",
      "Processed 78500 images of 100000\n",
      "Processed 79000 images of 100000\n",
      "Processed 79500 images of 100000\n",
      "Processed 80000 images of 100000\n",
      "Processed 80500 images of 100000\n",
      "Processed 81000 images of 100000\n",
      "Processed 81500 images of 100000\n",
      "Processed 82000 images of 100000\n",
      "Processed 82500 images of 100000\n",
      "Processed 83000 images of 100000\n",
      "Processed 83500 images of 100000\n",
      "Processed 84000 images of 100000\n",
      "Processed 84500 images of 100000\n",
      "Processed 85000 images of 100000\n",
      "Processed 85500 images of 100000\n",
      "Processed 86000 images of 100000\n",
      "Processed 86500 images of 100000\n",
      "Processed 87000 images of 100000\n",
      "Processed 87500 images of 100000\n",
      "Processed 88000 images of 100000\n",
      "Processed 88500 images of 100000\n",
      "Processed 89000 images of 100000\n",
      "Processed 89500 images of 100000\n",
      "Processed 90000 images of 100000\n",
      "Processed 90500 images of 100000\n",
      "Processed 91000 images of 100000\n",
      "Processed 91500 images of 100000\n",
      "Processed 92000 images of 100000\n",
      "Processed 92500 images of 100000\n",
      "Processed 93000 images of 100000\n",
      "Processed 93500 images of 100000\n",
      "Processed 94000 images of 100000\n",
      "Processed 94500 images of 100000\n",
      "Processed 95000 images of 100000\n",
      "Processed 95500 images of 100000\n",
      "Processed 96000 images of 100000\n",
      "Processed 96500 images of 100000\n",
      "Processed 97000 images of 100000\n",
      "Processed 97500 images of 100000\n",
      "Processed 98000 images of 100000\n",
      "Processed 98500 images of 100000\n",
      "Processed 99000 images of 100000\n",
      "Processed 99500 images of 100000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing demo/valid\n",
      "Processed 0 images of 20000\n",
      "Processed 500 images of 20000\n",
      "Processed 1000 images of 20000\n",
      "Processed 1500 images of 20000\n",
      "Processed 2000 images of 20000\n",
      "Processed 2500 images of 20000\n",
      "Processed 3000 images of 20000\n",
      "Processed 3500 images of 20000\n",
      "Processed 4000 images of 20000\n",
      "Processed 4500 images of 20000\n",
      "Processed 5000 images of 20000\n",
      "Processed 5500 images of 20000\n",
      "Processed 6000 images of 20000\n",
      "Processed 6500 images of 20000\n",
      "Processed 7000 images of 20000\n",
      "Processed 7500 images of 20000\n",
      "Processed 8000 images of 20000\n",
      "Processed 8500 images of 20000\n",
      "Processed 9000 images of 20000\n",
      "Processed 9500 images of 20000\n",
      "Processed 10000 images of 20000\n",
      "Processed 10500 images of 20000\n",
      "Processed 11000 images of 20000\n",
      "Processed 11500 images of 20000\n",
      "Processed 12000 images of 20000\n",
      "Processed 12500 images of 20000\n",
      "Processed 13000 images of 20000\n",
      "Processed 13500 images of 20000\n",
      "Processed 14000 images of 20000\n",
      "Processed 14500 images of 20000\n",
      "Processed 15000 images of 20000\n",
      "Processed 15500 images of 20000\n",
      "Processed 16000 images of 20000\n",
      "Processed 16500 images of 20000\n",
      "Processed 17000 images of 20000\n",
      "Processed 17500 images of 20000\n",
      "Processed 18000 images of 20000\n",
      "Processed 18500 images of 20000\n",
      "Processed 19000 images of 20000\n",
      "Processed 19500 images of 20000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Processing demo/test\n",
      "Processed 0 images of 20000\n",
      "Processed 500 images of 20000\n",
      "Processed 1000 images of 20000\n",
      "Processed 1500 images of 20000\n",
      "Processed 2000 images of 20000\n",
      "Processed 2500 images of 20000\n",
      "Processed 3000 images of 20000\n",
      "Processed 3500 images of 20000\n",
      "Processed 4000 images of 20000\n",
      "Processed 4500 images of 20000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5000 images of 20000\n",
      "Processed 5500 images of 20000\n",
      "Processed 6000 images of 20000\n",
      "Processed 6500 images of 20000\n",
      "Processed 7000 images of 20000\n",
      "Processed 7500 images of 20000\n",
      "Processed 8000 images of 20000\n",
      "Processed 8500 images of 20000\n",
      "Processed 9000 images of 20000\n",
      "Processed 9500 images of 20000\n",
      "Processed 10000 images of 20000\n",
      "Processed 10500 images of 20000\n",
      "Processed 11000 images of 20000\n",
      "Processed 11500 images of 20000\n",
      "Processed 12000 images of 20000\n",
      "Processed 12500 images of 20000\n",
      "Processed 13000 images of 20000\n",
      "Processed 13500 images of 20000\n",
      "Processed 14000 images of 20000\n",
      "Processed 14500 images of 20000\n",
      "Processed 15000 images of 20000\n",
      "Processed 15500 images of 20000\n",
      "Processed 16000 images of 20000\n",
      "Processed 16500 images of 20000\n",
      "Processed 17000 images of 20000\n",
      "Processed 17500 images of 20000\n",
      "Processed 18000 images of 20000\n",
      "Processed 18500 images of 20000\n",
      "Processed 19000 images of 20000\n",
      "Processed 19500 images of 20000\n"
     ]
    }
   ],
   "source": [
    "save_files('datasets/train', train_df)\n",
    "save_files('datasets/valid', valid_df)\n",
    "save_files('datasets/test', test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['full_path'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8a05c54fec97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'full_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ocr-detector/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ocr-detector/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ocr-detector/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ocr-detector/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5016\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5017\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5018\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5020\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['full_path'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train_df = train_df.drop('full_path', axis = 1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_path(prefix, df):\n",
    "    df['path'] = prefix + df['path']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5996700</th>\n",
       "      <td>Eerier</td>\n",
       "      <td>/datasets/train/408/3/125_Eerier_24690.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4416676</th>\n",
       "      <td>Begets</td>\n",
       "      <td>/datasets/train/944/3/62_Begets_6696.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950801</th>\n",
       "      <td>hutches</td>\n",
       "      <td>/datasets/train/1771/3/462_hutches_37481.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829770</th>\n",
       "      <td>lobbyist</td>\n",
       "      <td>/datasets/train/1141/4/369_lobbyist_44975.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786390</th>\n",
       "      <td>cheekiest</td>\n",
       "      <td>/datasets/train/814/6/233_cheekiest_12962.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                           path\n",
       "5996700     Eerier     /datasets/train/408/3/125_Eerier_24690.jpg\n",
       "4416676     Begets       /datasets/train/944/3/62_Begets_6696.jpg\n",
       "1950801    hutches   /datasets/train/1771/3/462_hutches_37481.jpg\n",
       "3829770   lobbyist  /datasets/train/1141/4/369_lobbyist_44975.jpg\n",
       "4786390  cheekiest  /datasets/train/814/6/233_cheekiest_12962.jpg"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = extend_path('/datasets/train', train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'helper' has no attribute 'store_dataframe_to_csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a85713a5e2cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/datasets/valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_dataframe_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/datasets/valid_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'helper' has no attribute 'store_dataframe_to_csv'"
     ]
    }
   ],
   "source": [
    "df = valid_df.copy()\n",
    "df = extend_path('/datasets/valid', df)\n",
    "hp.store_dataframe_to_csv(df, '/datasets/valid_df.csv', ['label', 'path'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
